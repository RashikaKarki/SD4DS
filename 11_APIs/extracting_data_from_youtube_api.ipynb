{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BkqEbyrrSd5D"
      },
      "outputs": [],
      "source": [
        "#import libraries\n",
        "import requests\n",
        "import pandas as pd\n",
        "import time"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yN5zGnx7XMNa"
      },
      "outputs": [],
      "source": [
        "#Keys\n",
        "API_KEY = \"AIzaSyDcPJcv5eszXoCVIr8SqsDH5yKwDZ7mGqM\"\n",
        "CHANNEL_ID = \"UC8pYaQzbBBXg9GIOHRvTmDQ\"     # MotoGP"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Sample API Call to Github"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Make API Call\n",
        "response = requests.get(\"https://api.github.com\").json()\n",
        "response"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Most of the work with APIs is passing the right URL with the correct parameters. In this case, we weren't passing any params. We'll see how complicated and difficult it can be working with parameters. The second difficult part is going through a response like this, parsing the right data and saving it in the right way. This can take quite a bit of time. But we will look at strategies to simplify the process. \n",
        "\n",
        "There's a lot of documentation you will need to read through to build out the right URL to get your desired response."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Extracting MotoGP Youtube Channel Stats\n",
        "Let's extract some data from the MotoGP youtube channel and collect data on videos, views, likes, comments, etc. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "pagetoken = \"\"\n",
        "url = \"https://www.googleapis.com/youtube/v3/search?key=\"+API_KEY+\"&channelId=\"+CHANNEL_ID+\"&part=snippet,id&order=date&maxResults=1000&\"+pageToken\n",
        "youtube_response = requests.get(url).json()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "When parsing through the json response, notice that the `items` key contains the bulk of the video information I am after. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "youtube_response"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "youtube_response['items']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Let's parse through the data now, starting with the first video. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "youtube_response['items'][0]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Let's extract the `videoId`, video `title` and `upload_date`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "youtube_response['items'][0]['id']['videoId']\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Now we can loop over all the videos in the response list and do our processing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "for video in youtube_response['items']:\n",
        "    if video['id']['kind'] == \"youtube#video\":\n",
        "        "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Now that we have a list of video ids, let's get the details for each video"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "video_id = 'V3WhJCwM9qk'\n",
        "video_stats = \"https://www.googleapis.com/youtube/v3/videos?id=\"+video_id+\"&part=statistics&key=\"+API_KEY\n",
        "response_video_stats_temp = requests.get(video_stats).json()\n",
        "response_video_stats_temp['items'][0]['statistics']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PuvL2HsqoJ8J"
      },
      "outputs": [],
      "source": [
        "def get_video_details(video_id):\n",
        "\n",
        "    #collecting view, like, dislike, comment counts\n",
        "    url_video_stats = \"https://www.googleapis.com/youtube/v3/videos?id=\"+video_id+\"&part=statistics&key=\"+API_KEY\n",
        "    response_video_stats = requests.get(url_video_stats).json()\n",
        "\n",
        "    view_count = response_video_stats['items'][0]['statistics']['viewCount']\n",
        "    like_count = response_video_stats['items'][0]['statistics']['likeCount']\n",
        "    # dislike_count = response_video_stats['items'][0]['statistics']['dislikeCount']\n",
        "    comment_count = response_video_stats['items'][0]['statistics']['commentCount']\n",
        "\n",
        "    return view_count, like_count, comment_count"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8l13hjKIdduW"
      },
      "outputs": [],
      "source": [
        "def get_videos(df):\n",
        "    pageToken = \"\"\n",
        "    url = \"https://www.googleapis.com/youtube/v3/search?key=\"+API_KEY+\"&channelId=\"+CHANNEL_ID+\"&part=snippet,id&order=date&maxResults=100&\"+pageToken\n",
        "\n",
        "    response = requests.get(url).json()\n",
        "    time.sleep(1) #give it a second before starting the for loop\n",
        "    rows = []\n",
        "    for video in response['items']:\n",
        "        if video['id']['kind'] == \"youtube#video\":\n",
        "            video_id = video['id']['videoId']\n",
        "            video_title = video['snippet']['title']\n",
        "            video_title = str(video_title).replace(\"&amp;\",\"\")\n",
        "            upload_date = video['snippet']['publishedAt']\n",
        "            upload_date = str(upload_date).split(\"T\")[0]\n",
        "            view_count, like_count, comment_count = get_video_details(video_id)\n",
        "\n",
        "            rows.append({\n",
        "            'video_id': video_id,\n",
        "            'video_title': video_title,\n",
        "            'upload_date': upload_date,\n",
        "            'view_count': view_count,\n",
        "            'like_count': like_count,\n",
        "            'comment_count': comment_count\n",
        "        })\n",
        "    \n",
        "    df = pd.concat([df, pd.DataFrame(rows)], ignore_index=True)\n",
        "    try:\n",
        "        if response['nextPageToken'] != None: #if none, it means it reached the last page and break out of it\n",
        "            pageToken = \"pageToken=\" + response['nextPageToken']\n",
        "    except KeyError as e:\n",
        "        print(f\"KeyError: {e} - 'nextPageToken' not found in the response.\")\n",
        "    except Exception as e:\n",
        "        print(f\"An unexpected error occurred: {e}\")\n",
        "\n",
        "    return df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v1NMEFet6kRC"
      },
      "outputs": [],
      "source": [
        "#main\n",
        "\n",
        "#build our dataframe\n",
        "motogp_df = pd.DataFrame(columns=[\"video_id\",\"video_title\",\"upload_date\",\"view_count\",\"like_count\",\"comment_count\"]) \n",
        "\n",
        "motogp_df = get_videos(motogp_df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "id": "laI5tSLSvkSx",
        "outputId": "2a575507-d2d6-4668-807a-a401a800b154"
      },
      "outputs": [],
      "source": [
        "motogp_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t8laAmHlY7Qw"
      },
      "outputs": [],
      "source": [
        "motogp_df.to_csv('youtube_vids_2nd_pull.csv')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### What did we learn?\n",
        "1. Learned about the python requests library to make API calls\n",
        "2. Learned to make API calls to Youtube API (choosing and composing the right URL params)\n",
        "3. Collected data as JSON\n",
        "4. Extracted data of interest to us from Youtube API response\n",
        "5. Saved data in a pandas dataframe\n",
        "6. Refactored code with good SWE fundamentals"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "extracting_data_from_youtube_api.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
