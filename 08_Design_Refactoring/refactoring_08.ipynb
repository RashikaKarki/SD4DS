{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Refactoring"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Fixing Duplicated Code by Pulling Up a Function\n",
    "\n",
    "Bad Code Smell: Duplicated Code\n",
    "Refactoring Motif: Pull Up Function\n",
    "\n",
    "Imagine you are trying to compare the performance of Adaboost versus RandomForest on the famous `Kaggle Titanic Competition`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "\n",
    "def load_df():\n",
    "    df = pd.read_csv('../data/titanic_dataset.csv')\n",
    "    df[\"is_male\"] = df[\"Sex\"] == \"male\"\n",
    "    return df\n",
    "\n",
    "\n",
    "def evaluate_adaboost_model(data):\n",
    "    X = data[[\"is_male\", \"SibSp\", \"Pclass\", \"Fare\"]]\n",
    "    y = data['Survived']\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "    \n",
    "    model = AdaBoostClassifier()\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    accuracy = model.score(X_test, y_test)\n",
    "    return accuracy\n",
    "\n",
    "\n",
    "def evaluate_random_forest_model(data):\n",
    "    X = data[[\"is_male\", \"SibSp\", \"Pclass\", \"Fare\"]]\n",
    "    y = data['Survived']\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "    \n",
    "    model = RandomForestClassifier()\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    accuracy = model.score(X_test, y_test)\n",
    "    return accuracy\n",
    "\n",
    "\n",
    "df = load_df()\n",
    "\n",
    "accuracy_adaboost = evaluate_adaboost_model(df)\n",
    "print(f\"AdaBoost Accuracy: {accuracy_adaboost:.3f}\")\n",
    "\n",
    "accuracy_random_forest = evaluate_random_forest_model(df)\n",
    "print(f\"Random Forest Accuracy: {accuracy_random_forest:.3f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And now, you want to add an additional comparison for XGBoost before handing it off to some engineers to run it on a much larger dataset. But first, you smell something is amiss… are you really going to create a new function, `evaluate_xgboost_model()`? `evaluate_adaboost_model()` and `evaluate_random_forest_model()` already appear to have a lot of repeated code that you’d have to copy and paste.\n",
    "\n",
    "Well, if you find yourself needing to copy and paste code, it’s usually a hint to refactor. To fix this case of duplicated code, we’ll use the “pull up function” refactoring, in which we extract a generalized version of two nearly identical functions*. More specifically, we’ll pull up a function `evaluate_model()`, which will take in the model of interest as an argument, thus deprecating `evaluate_adaboost_model()` and `evaluate_random_forest_model()`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "\n",
    "\n",
    "def load_df():\n",
    "    df = pd.read_csv('../data/titanic_dataset.csv')\n",
    "    df[\"is_male\"] = df[\"Sex\"] == \"male\"\n",
    "    return df\n",
    "\n",
    "\n",
    "#### PULLED UP METHOD ####\n",
    "def evaluate_model(data, model_constructor):\n",
    "    X = data[[\"is_male\", \"SibSp\", \"Pclass\", \"Fare\"]]\n",
    "    y = data['Survived']\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "    \n",
    "    model = model_constructor()\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    accuracy = model.score(X_test, y_test)\n",
    "    return accuracy\n",
    "\n",
    "\n",
    "df = load_df()\n",
    "\n",
    "accuracy_adaboost = evaluate_model(df, AdaBoostClassifier)\n",
    "print(f\"AdaBoost Accuracy: {accuracy_adaboost:.3f}\")\n",
    "\n",
    "accuracy_random_forest = evaluate_model(df, RandomForestClassifier)\n",
    "print(f\"Random Forest Accuracy: {accuracy_random_forest:.3f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instead of immediately putting on the “add features” hat, we took a moment, and put on the “refactor hat”. Without changing the observable behavior of the code, we managed to improve its internal design in such a way that not only did our code get shorter, but adding an extra model-evaluation for XGBoost (and any other model) is now trivial:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier\n",
    "\n",
    "\n",
    "accuracy_xgboost = evaluate_model(df, XGBClassifier)\n",
    "print(f\"XGBoost Accuracy: {accuracy_xgboost:.3f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Fixing a Mysterious Name by Renaming a Variable\n",
    "Bad Code Smell: Mysterious Name\n",
    "Refactoring Motif: Rename Variable\n",
    "\n",
    "Now, let’s say you got good results (yay!), so you show it to your colleague, who immediately interrupts you by saying “What’s actually in df though?”.\n",
    "\n",
    "Often, renaming a variable has the highest ratio of reward-to-effort of any refactoring motif; with a little bit of thought and just a few keystrokes, you can preemptively answer questions about the data that’s getting passed around your code. In this case, it should be easy to come up with a clear name that communicates precisely what’s inside of our dataframe; doing so will not only answer your colleague’s question, but it will preempt any other such questions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "\n",
    "#### RENAMED FUNCTION ####\n",
    "def load_titanic_passengers_df():\n",
    "    titanic_passengers_df = pd.read_csv('../data/titanic_dataset.csv')\n",
    "    titanic_passengers_df[\"is_male\"] = titanic_passengers_df[\"Sex\"] == \"male\"\n",
    "    return titanic_passengers_df\n",
    "\n",
    "\n",
    "def evaluate_model(data, model_constructor):\n",
    "    X = data[[\"is_male\", \"SibSp\", \"Pclass\", \"Fare\"]]\n",
    "    y = data['Survived']\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "    \n",
    "    model = model_constructor()\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    accuracy = model.score(X_test, y_test)\n",
    "    return accuracy\n",
    "\n",
    "\n",
    "#### RENAMED VARIABLE ####\n",
    "titanic_passengers_df = load_titanic_passengers_df()\n",
    "\n",
    "accuracy_adaboost = evaluate_model(titanic_passengers_df, AdaBoostClassifier)\n",
    "print(f\"AdaBoost Accuracy: {accuracy_adaboost:.3f}\")\n",
    "\n",
    "accuracy_random_forest = evaluate_model(titanic_passengers_df, RandomForestClassifier)\n",
    "print(f\"Random Forest Accuracy: {accuracy_random_forest:.3f}\")\n",
    "\n",
    "accuracy_xgboost = evaluate_model(df, XGBClassifier)\n",
    "print(f\"XGBoost Accuracy: {accuracy_xgboost:.3f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After renaming `df` to `titanic_passengers_df` and `load_df()` to `load_titanic_passengers_df()`, there’s no doubt at all – every row in the newly named `titanic_passengers_df` represents a distinct passenger from the Titanic. Nice!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Fix Magic Values by Extracting Variables\n",
    "Bad Code Smell: Magic Values\n",
    "Refactoring Motif: Extract Variable\n",
    "\n",
    "So you’ve discussed it to your colleagues, and they all agree: you’ve got some great results! Now, it’s time to share it with the engineers in your team to scale it to more data; the only problem is that the engineers are not so familiar with data science and machine learning, and they immediately ask “what are these string values at the top of the evaluate_model function?”.\n",
    "\n",
    "Instead of saying “they’re features and a target for our model, silly engineer!”, we can answer all engineers’ such questions permanently by extracting the requisite variables from our code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "\n",
    "#### EXTRACTED VARIABLES ####\n",
    "MODEL_FEATURES = [\"is_male\", \"SibSp\", \"Pclass\", \"Fare\"]\n",
    "MODEL_TARGET = \"Survived\"\n",
    "TRAIN_TEST_SPLIT_FRACTION = 0.2\n",
    "\n",
    "\n",
    "def load_titanic_passengers_df():\n",
    "    titanic_passengers_df = pd.read_csv('../data/titanic_dataset.csv')\n",
    "    titanic_passengers_df[\"is_male\"] = titanic_passengers_df[\"Sex\"] == \"male\"\n",
    "    return titanic_passengers_df\n",
    "\n",
    "\n",
    "def evaluate_model(data, model_constructor):\n",
    "    X = data[MODEL_FEATURES]\n",
    "    y = data[MODEL_TARGET]\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=TRAIN_TEST_SPLIT_FRACTION)\n",
    "    \n",
    "    model = model_constructor()\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    accuracy = model.score(X_test, y_test)\n",
    "    return accuracy\n",
    "\n",
    "\n",
    "titanic_passengers_df = load_df()\n",
    "\n",
    "accuracy_adaboost = evaluate_model(titanic_passengers_df, AdaBoostClassifier)\n",
    "print(f\"AdaBoost Accuracy: {accuracy_adaboost:.3f}\")\n",
    "\n",
    "accuracy_random_forest = evaluate_model(titanic_passengers_df, RandomForestClassifier)\n",
    "print(f\"Random Forest Accuracy: {accuracy_random_forest:.3f}\")\n",
    "\n",
    "accuracy_xgboost = evaluate_model(df, XGBClassifier)\n",
    "print(f\"XGBoost Accuracy: {accuracy_xgboost:.3f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the `MODEL_FEATURES` and `MODEL_TARGET` variables extracted, we significantly decrease ambiguity for future readers (and we extracted the `TRAIN_TEST_SPLIT_FRACTION` in case of future questions regarding that as well).\n",
    "\n",
    "In summary, we:\n",
    "\n",
    "Fixed duplicated code by pulling up the `evaluate_model()` function;\n",
    "Fixed the mysterious df name by renaming it to `titanic_passengers_df`; and\n",
    "Fixed the magic values in our code by extracting the variables `MODEL_FEATURES`, `MODEL_TARGET`, and `TRAIN_TEST_SPLIT_FRACTION`.\n",
    "Adding that extra evaluation for XGBoost was not only easier, but our code has become more readable to all audiences who are likely to interact with it.\n",
    "\n",
    "There’s still plenty more refactoring that can be done to this code, but for now, it’s enough. Once it’s time to add the next piece of new functionality to the code, then the next most important refactoring will reveal itself."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using the dataclasseses Module"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In Python, a data class is a class that is designed to only hold data values. They aren't different from regular classes, but they usually don't have any other methods. They are typically used to store information that will be passed between different parts of a program or a system.\n",
    "\n",
    "However, when creating classes to work only as data containers, writing the __init__ method repeatedly can generate a great amount of work and potential errors.\n",
    "\n",
    "The dataclasses module, a feature introduced in Python 3.7, provides a way to create data classes in a simpler manner without the need to write methods. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ManualComment:\n",
    "    def __init__(self, id: int, text: str):\n",
    "        self.id: int = id\n",
    "        self.text: str = text\n",
    "\n",
    "    # @property\n",
    "    def id(self) -> int:\n",
    "        return self.id\n",
    "    \n",
    "    def text(self) -> str:\n",
    "        return self.text\n",
    "\n",
    "    def __repr__(self):\n",
    "        return \"{}(id={}, text={})\".format(self.__class__.__name__, self.id, self.text)\n",
    "\n",
    "    def __eq__(self, other):\n",
    "        if other.__class__ is self.__class__:\n",
    "            return (self.id, self.text) == (other.id, other.text)\n",
    "        else:\n",
    "            return NotImplemented\n",
    "\n",
    "    def __ne__(self, other):\n",
    "        result = self.__eq__(other)\n",
    "        if result is NotImplemented:\n",
    "            return NotImplemented\n",
    "        else:\n",
    "            return not result\n",
    "\n",
    "    def __hash__(self):\n",
    "        return hash((self.__class__, self.id, self.text))\n",
    "\n",
    "    def __lt__(self, other):\n",
    "        if other.__class__ is self.__class__:\n",
    "            return (self.id, self.text) < (other.id, other.text)\n",
    "        else:\n",
    "            return NotImplemented\n",
    "\n",
    "    def __le__(self, other):\n",
    "        if other.__class__ is self.__class__:\n",
    "            return (self.id, self.text) <= (other.id, other.text)\n",
    "        else:\n",
    "            return NotImplemented\n",
    "\n",
    "    def __gt__(self, other):\n",
    "        if other.__class__ is self.__class__:\n",
    "            return (self.id, self.text) > (other.id, other.text)\n",
    "        else:\n",
    "            return NotImplemented\n",
    "\n",
    "    def __ge__(self, other):\n",
    "        if other.__class__ is self.__class__:\n",
    "            return (self.id, self.text) >= (other.id, other.text)\n",
    "        else:\n",
    "            return NotImplemented"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here's how you would create the same `Comment` representation using a dataclass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dataclasses\n",
    "from dataclasses import dataclass, field\n",
    "\n",
    "@dataclass(frozen=True, order=True)\n",
    "class Comment:\n",
    "    id: int\n",
    "    text: str = \"\"\n",
    "    # replies: list[int] = field(default_factory=list, repr=False, compare=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Comment(id=1, text='I just subscribed!')\n",
      "[('__delattr__', <function Comment.__delattr__ at 0x00000211A3CEE4D0>),\n",
      " ('__eq__', <function Comment.__eq__ at 0x00000211A3CEDE10>),\n",
      " ('__ge__', <function Comment.__ge__ at 0x00000211A3CEE320>),\n",
      " ('__gt__', <function Comment.__gt__ at 0x00000211A3CEE170>),\n",
      " ('__hash__', <function Comment.__hash__ at 0x00000211A3CEE560>),\n",
      " ('__init__', <function Comment.__init__ at 0x00000211A3CED6C0>),\n",
      " ('__le__', <function Comment.__le__ at 0x00000211A3CEE050>),\n",
      " ('__lt__', <function Comment.__lt__ at 0x00000211A3CECA60>),\n",
      " ('__repr__', <function Comment.__repr__ at 0x00000211A3CED510>),\n",
      " ('__setattr__', <function Comment.__setattr__ at 0x00000211A3CEE3B0>)]\n"
     ]
    }
   ],
   "source": [
    "import inspect\n",
    "from pprint import pprint\n",
    "\n",
    "comment = Comment(1, \"I just subscribed!\")\n",
    "# comment.id = 3  # can't immutable\n",
    "print(comment)\n",
    "# print(dataclasses.astuple(comment))\n",
    "# print(dataclasses.asdict(comment))\n",
    "\n",
    "# pprint(inspect.getmembers(Comment, inspect.isfunction))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "SD4DS",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
